{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "esim.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "l4AumUIlD4Ru",
        "YC9CMsEND4R_",
        "CXk6Dh16D4SC",
        "yBIce13wD4SK",
        "X6uWfzsyD4SK"
      ]
    },
    "file_extension": ".py",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "mimetype": "text/x-python",
    "name": "python",
    "npconvert_exporter": "python",
    "pygments_lexer": "ipython3",
    "version": 3
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIyaC7ybKpxp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-E6nhMQ1JYA"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_json('data/IMDB_reviews.json')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0CChsu51YRO"
      },
      "source": [
        "import random\n",
        "\n",
        "# The data to load\n",
        "f = \"data/train.csv\"\n",
        "\n",
        "# Count the lines\n",
        "num_lines = 100000#sum(1 for l in open(f))\n",
        "\n",
        "# Sample size - in this case ~10%\n",
        "size = int(num_lines / 10)\n",
        "\n",
        "# The row indices to skip - make sure 0 is not included to keep the header!\n",
        "skip_idx = random.sample(range(1, num_lines), num_lines - size)\n",
        "\n",
        "# Read the data\n",
        "df = pd.read_csv('data/train.csv',nrows=100000,skiprows=skip_idx)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBEJMl3W61-4",
        "outputId": "5a4f3071-e7cc-4147-ea5c-82de8b84626b"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZbshTHF1JVk",
        "outputId": "fd8770d9-bd7f-458e-bb62-d17d6fbb3613"
      },
      "source": [
        "df.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['movie_id', 'sentence1', 'sentence2', 'label'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rET2BdG11JTD"
      },
      "source": [
        "df = df.sort_values(by='movie_id')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "NpWuhwnO1JQi",
        "outputId": "c819a588-486d-481b-da4c-195c054f1192"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>movie_id</th>\n",
              "      <th>sentence1</th>\n",
              "      <th>sentence2</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4842</th>\n",
              "      <td>tt0012349</td>\n",
              "      <td>The opening title reads: \"A comedy with a smil...</td>\n",
              "      <td>Not a big fan of silent movies... ...but I was...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4628</th>\n",
              "      <td>tt0012349</td>\n",
              "      <td>The opening title reads: \"A comedy with a smil...</td>\n",
              "      <td>Old but still refreshing. People of our genera...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6830</th>\n",
              "      <td>tt0012349</td>\n",
              "      <td>The opening title reads: \"A comedy with a smil...</td>\n",
              "      <td>A classic in every sense of the word There are...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6835</th>\n",
              "      <td>tt0012349</td>\n",
              "      <td>The opening title reads: \"A comedy with a smil...</td>\n",
              "      <td>One of the greatest films of all-time The Kid ...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3243</th>\n",
              "      <td>tt0012349</td>\n",
              "      <td>The opening title reads: \"A comedy with a smil...</td>\n",
              "      <td>A comedy classic Charlie Chaplin's 1921 master...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       movie_id  ...  label\n",
              "4842  tt0012349  ...  False\n",
              "4628  tt0012349  ...  False\n",
              "6830  tt0012349  ...  False\n",
              "6835  tt0012349  ...   True\n",
              "3243  tt0012349  ...   True\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEhbrsNv1JMg"
      },
      "source": [
        "df1 = pd.DataFrame(columns=df.columns)\n",
        "\n",
        "for i in set(df['movie_id']):\n",
        "  # print(i)\n",
        "  # print(df.loc[df['movie_id'] == i])\n",
        "  df1 = df1.append(df.loc[df['movie_id'] == i].iloc[0:10])\n",
        "  # x = df.loc[df['movie_id'] == i].iloc[0:10]\n",
        "  # print('x',x.head())\n",
        "  # break\n",
        "# df1.append(x)\n",
        "# print(df1)\n",
        "# print(type(x))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UX6DjBN45vv6"
      },
      "source": [
        "df1['movie_id'].unique().shape\n",
        "df1.to_csv('data/movie_reviews.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyVvyq3Z7vYw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6abfaf0f-1877-4635-b382-3257cb2b5fe4"
      },
      "source": [
        "\n",
        "!pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Spoiler detection/spoiler-detector\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "zg9udlpg35hz",
        "outputId": "709514dd-21b2-41b4-c07f-7f96a01cccfd"
      },
      "source": [
        "df1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>movie_id</th>\n",
              "      <th>sentence1</th>\n",
              "      <th>sentence2</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>346</th>\n",
              "      <td>tt0125664</td>\n",
              "      <td>At the beginning, Kaufman's foreign man comes ...</td>\n",
              "      <td>Controversial... but I loved it! This is a fil...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>229</th>\n",
              "      <td>tt0118880</td>\n",
              "      <td>Cameron Poe (Nicholas Cage), a honorably disch...</td>\n",
              "      <td>\"Con Air\" - What a wild ride! I have to say th...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111</th>\n",
              "      <td>tt0357413</td>\n",
              "      <td>In the mid 1970's, Ron Burgundy (Will Ferrell)...</td>\n",
              "      <td>best comedy i have seen in years Two summers a...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>271</th>\n",
              "      <td>tt0129167</td>\n",
              "      <td>In 1957, a large alien robot crashes from orbi...</td>\n",
              "      <td>A Masterpiece... There's a moment in the Iron ...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>tt1182345</td>\n",
              "      <td>The film begins with a commercial from Lunar I...</td>\n",
              "      <td>Ohh.... The concept smooth simple.... Acting d...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>710</th>\n",
              "      <td>tt0078788</td>\n",
              "      <td>The story opens in Saigon late in 1969. U.S. A...</td>\n",
              "      <td>Gives to cinema what Shakespeare gave to the s...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>713</th>\n",
              "      <td>tt0120738</td>\n",
              "      <td>In the year 2058, Earth will soon be uninhabit...</td>\n",
              "      <td>Possibly The Worst Movie EVER! I am a huge fan...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>tt0120738</td>\n",
              "      <td>In the year 2058, Earth will soon be uninhabit...</td>\n",
              "      <td>Made(poorly) for kids With a pseudo-infant CGI...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>447</th>\n",
              "      <td>tt0110729</td>\n",
              "      <td>This film is about a Maori family living in Au...</td>\n",
              "      <td>brilliant exposure of domestic violence the au...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>703</th>\n",
              "      <td>tt0416449</td>\n",
              "      <td>Spartan customs are harsh. The Spartans inspec...</td>\n",
              "      <td>Despite Several Flaws A Very Memorable Movie H...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      movie_id  ...  label\n",
              "346  tt0125664  ...  False\n",
              "229  tt0118880  ...  False\n",
              "111  tt0357413  ...  False\n",
              "271  tt0129167  ...  False\n",
              "33   tt1182345  ...   True\n",
              "..         ...  ...    ...\n",
              "710  tt0078788  ...  False\n",
              "713  tt0120738  ...  False\n",
              "79   tt0120738  ...  False\n",
              "447  tt0110729  ...  False\n",
              "703  tt0416449  ...  False\n",
              "\n",
              "[1000 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72aEEjznEB6C",
        "outputId": "527d05cc-8edd-42b8-cc43-fea5125e955a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd drive/MyDrive/Spoiler\\ detection/spoiler-detector\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "[Errno 2] No such file or directory: 'drive/MyDrive/Spoiler detection/spoiler-detector'\n",
            "/content/drive/MyDrive/Spoiler detection/spoiler-detector\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptpBQIXI0mIE",
        "outputId": "0f3e323f-20ee-445a-ba50-3cf7a3ebf4c2"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Spoiler detection/spoiler-detector\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RcXdUjpHED9X",
        "outputId": "4484d437-eb0a-4f77-e12c-ee5a58b555ff"
      },
      "source": [
        "!pip install mxnet-cu110\n",
        "# !pip install mxnet\n",
        "!pip install gluonnlp"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mxnet-cu110\n",
            "  Downloading mxnet_cu110-1.8.0.post0-py2.py3-none-manylinux2014_x86_64.whl (323.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 323.5 MB 403 bytes/s \n",
            "\u001b[?25hCollecting graphviz<0.9.0,>=0.8.1\n",
            "  Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.7/dist-packages (from mxnet-cu110) (1.19.5)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet-cu110) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet-cu110) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet-cu110) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet-cu110) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet-cu110) (2021.5.30)\n",
            "Installing collected packages: graphviz, mxnet-cu110\n",
            "  Attempting uninstall: graphviz\n",
            "    Found existing installation: graphviz 0.10.1\n",
            "    Uninstalling graphviz-0.10.1:\n",
            "      Successfully uninstalled graphviz-0.10.1\n",
            "Successfully installed graphviz-0.8.4 mxnet-cu110-1.8.0.post0\n",
            "Collecting gluonnlp\n",
            "  Downloading gluonnlp-0.10.0.tar.gz (344 kB)\n",
            "\u001b[K     |████████████████████████████████| 344 kB 4.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (1.19.5)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (0.29.23)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (21.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->gluonnlp) (2.4.7)\n",
            "Building wheels for collected packages: gluonnlp\n",
            "  Building wheel for gluonnlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gluonnlp: filename=gluonnlp-0.10.0-cp37-cp37m-linux_x86_64.whl size=595744 sha256=90e55050201d9b06a3e58434ed373660cc9480afed167bb5aafd491db016d378\n",
            "  Stored in directory: /root/.cache/pip/wheels/be/b4/06/7f3fdfaf707e6b5e98b79c041e023acffbe395d78a527eae00\n",
            "Successfully built gluonnlp\n",
            "Installing collected packages: gluonnlp\n",
            "Successfully installed gluonnlp-0.10.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4AumUIlD4Ru"
      },
      "source": [
        "## Enhanced Sequence Inference Model\n",
        "(https://arxiv.org/abs/1609.06038).\n",
        "\n",
        "\n",
        "### Import Related Packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdv_PP6XLneL"
      },
      "source": [
        "Implementation referred from https://github.com/zhiming-xu/spoiler-detector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpEyPdqKD4Ry"
      },
      "source": [
        "import os\n",
        "import json\n",
        "import zipfile\n",
        "import time\n",
        "import itertools\n",
        "\n",
        "import numpy as np\n",
        "import mxnet as mx\n",
        "import multiprocessing as mp\n",
        "import gluonnlp as nlp\n",
        "\n",
        "from mxnet import gluon, nd, init\n",
        "from mxnet.gluon import nn, rnn\n",
        "from mxnet import autograd, gluon, nd\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# sklearn's metric function to evaluate the results of the experiment\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "# fixed random number seed\n",
        "np.random.seed(9102)\n",
        "mx.random.seed(9102)\n",
        "def try_gpu():\n",
        "    \"\"\"If GPU is available, return mx.gpu(0); else return mx.cpu().\"\"\"\n",
        "    try:\n",
        "        ctx = mx.gpu()\n",
        "        _ = nd.array([0], ctx=ctx)\n",
        "    except:\n",
        "        ctx = mx.cpu()\n",
        "    return ctx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSjmeIo3D4R0"
      },
      "source": [
        "## Data pipeline\n",
        "\n",
        "### Load Dataset\n",
        "\n",
        "See [dataloader](data_loader.ipynb) for how the training samples are obtained."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tgBiweY1D4R1",
        "outputId": "de7e0ae8-ff4d-4a5c-f029-1409e52dae8c"
      },
      "source": [
        "data_folder = 'data/'\n",
        "file_name = 'train.csv'\n",
        "file_path = data_folder + file_name\n",
        "# dev: True - only use a small dataset\n",
        "# create_vocab: True - create a new vocabulary from training data\n",
        "dev = True\n",
        "# load train file\n",
        "if dev:\n",
        "    # load only n rows\n",
        "    nrows = 5000\n",
        "    data = pd.read_csv(file_path, nrows=nrows)\n",
        "else:\n",
        "    # load as many as possible\n",
        "    data = pd.read_csv(file_path)\n",
        "data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqBQle4TD4R3",
        "outputId": "e26560f7-77f1-42e0-9ad5-80f82a879b51"
      },
      "source": [
        "data.dropna(inplace=True)\n",
        "data.shape, data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((5000, 4),     movie_id  ...  label\n",
              " 0  tt2802144  ...  False\n",
              " 1  tt2094766  ...   True\n",
              " 2  tt0335345  ...  False\n",
              " 3  tt0120611  ...  False\n",
              " 4  tt0086190  ...   True\n",
              " \n",
              " [5 rows x 4 columns])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8WKXdjRD4R4"
      },
      "source": [
        "label2num = {'contradiction':0, 'neutral':1, 'entailment':2} #1 not spoiler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKvWv0VVD4R5",
        "outputId": "f63474cb-7e31-44a0-c200-237062835de5"
      },
      "source": [
        "# create a list of review a label paris.\n",
        "dataset = [[left, right, label] for left, right, label in \\\n",
        "           zip(data['sentence1'], data['sentence2'], data['label']) if label!='-' ]\n",
        "# randomly divide one percent from the training set as a verification set.\n",
        "train_dataset, valid_dataset = nlp.data.train_valid_split(dataset, valid_ratio=.1)\n",
        "len(train_dataset), len(valid_dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4500, 500)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skeSiZE8D4R7"
      },
      "source": [
        "# train_dataset[100]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dxi16vLnvxea"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3raNtum_wd6Q",
        "outputId": "47f0ec8b-31ea-479a-a85d-a4b196c749fe"
      },
      "source": [
        "# tokenizer takes as input a string and outputs a list of tokens.\n",
        "tokenizer = nlp.data.SpacyTokenizer('en')\n",
        "length_review = 300\n",
        "length_plot = 600\n",
        "\n",
        "from src.util import mp_tokenizer\n",
        "\n",
        "tokenizer = mp_tokenizer(tokenizer, length_review, length_plot)\n",
        "\n",
        "# Preprocess the dataset\n",
        "train_dataset_token, train_data_lengths = tokenizer.process_dataset(train_dataset)\n",
        "valid_dataset_token, valid_data_lengths = tokenizer.process_dataset(valid_dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done! Sequence clipping and get length Time=88.38s, #Sentences=4500\n",
            "Done! Sequence clipping and get length Time=34.46s, #Sentences=500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGTroHJpwh34"
      },
      "source": [
        "from src.util import mp_indexer\n",
        "embedding = 'glove.42B.300d'\n",
        "indexer = mp_indexer(train_dataset_token, embedding)\n",
        "train_dataset = indexer.process_dataset(train_dataset_token)\n",
        "valid_dataset = indexer.process_dataset(valid_dataset_token)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kxo7g6wWvIMZ"
      },
      "source": [
        "import pickle\n",
        "\n",
        "# # saving\n",
        "# with open('tokenizer.pickle', 'wb') as handle:\n",
        "#     pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "# with open('train_dataset.pickle', 'wb') as handle:\n",
        "#     pickle.dump(train_dataset, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "\n",
        "# with open('valid_dataset.pickle', 'wb') as handle:\n",
        "#     pickle.dump(valid_dataset, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "# with open('train_data_lengths.pickle', 'wb') as handle:\n",
        "#     pickle.dump(train_data_lengths, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "# with open('valid_data_lengths.pickle', 'wb') as handle:\n",
        "#     pickle.dump(valid_data_lengths, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "# with open('indexer.pickle', 'wb') as handle:\n",
        "#     pickle.dump(indexer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "\n",
        "# # loading\n",
        "# with open('tokenizer.pickle', 'rb') as handle:\n",
        "#     tokenizer = pickle.load(handle)\n",
        "# with open('train_dataset.pickle', 'rb') as handle:\n",
        "#     train_dataset = pickle.load(handle)\n",
        "# with open('valid_dataset.pickle', 'rb') as handle:\n",
        "#     valid_dataset = pickle.load(handle)\n",
        "# with open('train_data_lengths.pickle', 'rb') as handle:\n",
        "#     train_data_lengths = pickle.load(handle)\n",
        "# with open('valid_data_lengths.pickle', 'rb') as handle:\n",
        "#     valid_data_lengths = pickle.load(handle)\n",
        "# with open('indexer.pickle', 'rb') as handle:\n",
        "#     indexer = pickle.load(handle)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUqMkQnID4R9"
      },
      "source": [
        "# tokenizer takes as input a string and outputs a list of tokens.\n",
        "tokenizer = nlp.data.SpacyTokenizer('en')\n",
        "length_review = 300\n",
        "length_plot = 600\n",
        "\n",
        "from src.util import mp_tokenizer\n",
        "\n",
        "tokenizer = mp_tokenizer(tokenizer, length_review, length_plot)\n",
        "\n",
        "# Preprocess the dataset\n",
        "train_dataset_token, train_data_lengths = tokenizer.process_dataset(train_dataset)\n",
        "valid_dataset_token, valid_data_lengths = tokenizer.process_dataset(valid_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpD-L4owD4R-"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aj5uE2LDD4R-"
      },
      "source": [
        "len(train_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YC9CMsEND4R_"
      },
      "source": [
        "### Bucketing and DataLoader\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vH7OAekD4SA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7de8b7c-0acd-4502-8d19-46d576820d98"
      },
      "source": [
        "batch_size = 32\n",
        "bucket_num = 10\n",
        "bucket_ratio = 0.5\n",
        "\n",
        "\n",
        "def get_dataloader():\n",
        "    # Construct the DataLoader pad data, stack label and lengths\n",
        "    batchify_fn = nlp.data.batchify.Tuple(nlp.data.batchify.Pad(axis=0), \\\n",
        "                                          nlp.data.batchify.Pad(axis=0),\n",
        "                                          nlp.data.batchify.Stack())\n",
        "\n",
        "    # n this example, we use a FixedBucketSampler,\n",
        "    # which assigns each data sample to a fixed bucket based on its length.\n",
        "    batch_sampler = nlp.data.sampler.FixedBucketSampler(\n",
        "        train_data_lengths,\n",
        "        batch_size=batch_size,\n",
        "        num_buckets=bucket_num,\n",
        "        ratio=bucket_ratio,\n",
        "        shuffle=True)\n",
        "    print(batch_sampler.stats())\n",
        "\n",
        "    # train_dataloader\n",
        "    train_dataloader = gluon.data.DataLoader(\n",
        "        dataset=train_dataset,\n",
        "        batch_sampler=batch_sampler,\n",
        "        batchify_fn=batchify_fn)\n",
        "    # valid_dataloader\n",
        "    valid_dataloader = gluon.data.DataLoader(\n",
        "        dataset=valid_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        batchify_fn=batchify_fn)\n",
        "    return train_dataloader, valid_dataloader\n",
        "\n",
        "train_dataloader, valid_dataloader = get_dataloader()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gluonnlp/data/batchify/batchify.py:235: UserWarning: Padding value is not given and will be set automatically to 0 in data.batchify.Pad(). Please check whether this is intended (e.g. value of padding index in the vocabulary).\n",
            "  'Padding value is not given and will be set automatically to 0 '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "FixedBucketSampler:\n",
            "  sample_num=4500, batch_num=144\n",
            "  key=[57, 84, 111, 138, 165, 192, 219, 246, 273, 300]\n",
            "  cnt=[26, 75, 52, 68, 35, 37, 61, 15, 10, 4121]\n",
            "  batch_size=[84, 57, 43, 34, 32, 32, 32, 32, 32, 32]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXk6Dh16D4SC",
        "scrolled": true
      },
      "source": [
        "### Weighted softmax cross entropy loss\n",
        "For a regular cross entropy loss, it is calculated by $-\\vec{y}^\\mathsf{T}\\log \\hat{\\vec{y}}$. Since $\\vec{y}$ is actually one-hot, so the value is $-\\log\\hat{y}_i$ where $i$ is the true label's index. To apply weight on this label, we multiply it with some weight value $w_i$, therefore, the loss of class $i$ is $-w_i\\log\\hat{y}_i$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6BhGgM7D4SC"
      },
      "source": [
        "# mx.Context(mx.gpu(0))\n",
        "class WeightedSoftmaxCE(nn.HybridBlock):\n",
        "    def __init__(self, sparse_label=True, from_logits=False,  **kwargs):\n",
        "        super(WeightedSoftmaxCE, self).__init__(**kwargs)\n",
        "        with self.name_scope():\n",
        "            self.sparse_label = sparse_label\n",
        "            self.from_logits = from_logits\n",
        "\n",
        "    def hybrid_forward(self, F, pred, label, class_weight, depth=None):\n",
        "        if self.sparse_label:\n",
        "            label = F.reshape(label, shape=(-1, ))\n",
        "            label = F.one_hot(label, depth)\n",
        "        if not self.from_logits:\n",
        "            pred = F.log_softmax(pred, -1)\n",
        "\n",
        "        weight_label = F.broadcast_mul(label, class_weight)\n",
        "        loss = -F.sum(pred * weight_label, axis=-1)\n",
        "        \n",
        "        return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIYJssB3D4SD"
      },
      "source": [
        "class AlignAttention(nn.Block):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(AlignAttention, self).__init__(**kwargs)\n",
        "    \n",
        "    def forward(self, inp_left, inp_right):\n",
        "        # input dimension is of (batch_size, seq_len, embed_size)\n",
        "        # att dimension is of (batch_size, seq_len_left, seq_len_right)\n",
        "        att = nd.batch_dot(inp_left, nd.transpose(inp_right, axes = (0, 2, 1)))\n",
        "        # inp_left_dot dimention is of (batch_size, seq_left, embed_size)\n",
        "        inp_left_dot = nd.batch_dot(nd.softmax(att, axis=-1), inp_right)\n",
        "        # inp_right_dot dimension is of (batch_size, seq_right, embed_size)\n",
        "        inp_right_dot = nd.batch_dot(nd.softmax(nd.transpose(att, axes=(0, 2, 1)), axis=-1), inp_left)\n",
        "        # concat original (lstm output, dot multiplier, substraction, elementwise product)\n",
        "        # therefore, the real size is (batch_size, seq_len_left/right, embed_size*4)\n",
        "        aug_left = nd.concat(inp_left, inp_left_dot, inp_left-inp_left_dot, inp_left*inp_left_dot, dim=-1)\n",
        "        aug_right = nd.concat(inp_right, inp_right_dot, inp_right-inp_right_dot, inp_right*inp_right_dot, dim=-1)\n",
        "        return aug_left, aug_right, att"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AaU3nVtD4SE"
      },
      "source": [
        "class EnhancedSeqInfer(nn.Block):\n",
        "    def __init__(self, vocab_len, embsize, nhidden, nlayers, nfc, nclass, drop_prob, **kwargs):\n",
        "        super(EnhancedSeqInfer, self).__init__(**kwargs)\n",
        "        with self.name_scope():\n",
        "            # dropout prob\n",
        "            self.drop_prob = drop_prob\n",
        "            # word embedding\n",
        "            self.embedding_layer = nn.Embedding(vocab_len, embsize)\n",
        "            # first lstm, from sentence embed to hidden outputs\n",
        "            self.bilstm1 = rnn.LSTM(nhidden, num_layers=nlayers, dropout=drop_prob, bidirectional=True)\n",
        "            # second lstm, from augmented embed to m\n",
        "            self.bilstm2 = rnn.LSTM(nhidden, num_layers=1, dropout=drop_prob, bidirectional=True)\n",
        "            # enhancement\n",
        "            self.align_att = AlignAttention()\n",
        "            # this layer is used to output the final class\n",
        "            self.output_layer = nn.HybridSequential()\n",
        "            self.output_layer.add(nn.Dense(nfc, activation='tanh'), nn.Dropout(rate=drop_prob), \\\n",
        "                                  nn.Dense(nfc, activation='tanh'), nn.Dropout(rate=drop_prob), \\\n",
        "                                  nn.Dense(nclass))\n",
        "\n",
        "    def forward(self, inp_left, inp_right):\n",
        "        # inp is a list containing left_text and right_text\n",
        "        # their size: [batch, token_idx]\n",
        "        # inp_embed_left/right size: [batch, seq_len, embed_size]\n",
        "        inp_embed_left = self.embedding_layer(inp_left)\n",
        "        inp_embed_right = self.embedding_layer(inp_right)\n",
        "        # rnn requires the first dimension to be the time steps, output is (seq_len, batch_size, embed_size)\n",
        "        h_output_left = self.bilstm1(nd.transpose(inp_embed_left, axes=(1, 0, 2)))\n",
        "        h_output_right = self.bilstm1(nd.transpose(inp_embed_right, axes=(1, 0, 2)))\n",
        "        m_left, m_right, att = self.align_att(nd.transpose(h_output_left, axes=(1, 0, 2)), \\\n",
        "                                                      nd.transpose(h_output_right, axes=(1, 0, 2)))\n",
        "        # apply another layer of lstm\n",
        "        # v_left/right shape is (seq_len, batch_size, embed_size)\n",
        "        v_left = self.bilstm2(nd.transpose(m_left, axes=(1, 0, 2)))\n",
        "        v_right = self.bilstm2(nd.transpose(m_right, axes=(1, 0, 2)))\n",
        "        # restore v's shape (batch_size, seq_len, embed_size)\n",
        "        v_left = nd.transpose(v_left, axes=(1, 0, 2))\n",
        "        v_right = nd.transpose(v_right, axes=(1, 0, 2))\n",
        "        # apply max pooling 1D and avg pooling 1D\n",
        "        v_left_avg = nd.sum(v_left, axis=1) / v_left.shape[1]\n",
        "        v_right_avg = nd.sum(v_right, axis=1) / v_right.shape[1]\n",
        "        v_left_max = nd.max(v_left, axis=1)\n",
        "        v_right_max = nd.max(v_right, axis=1)\n",
        "        # concatenate these 4 matrices\n",
        "        dense_input = nd.concat(v_left_avg, v_left_max, v_right_avg, v_left_max, dim=-1)\n",
        "        \n",
        "        output = self.output_layer(dense_input)\n",
        "        return output, att"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wzkK1Y5D4SE"
      },
      "source": [
        "### Configure parameters and build models\n",
        "`test_model` is set to `True` if we want to just load parameters and test on the model. Otherwise, it is set to `False` during training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IydG8WwWS6bs"
      },
      "source": [
        "# vocab_len"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaB9B9hhD4SF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9757ce64-a9ec-41e6-d348-d36c7f8bb02e"
      },
      "source": [
        "test_model = False\n",
        "vocab_len = len(indexer.vocab)\n",
        "emsize = 300    # word embedding size\n",
        "nhidden = 300   # lstm hidden_dim\n",
        "nlayers = 2     # lstm layers\n",
        "\n",
        "# final fc layer's number of hidden units and predicted number of classes\n",
        "nfc = 256\n",
        "nclass = 2\n",
        "\n",
        "drop_prob = 0.5\n",
        "\n",
        "ctx = mx.gpu(0)\n",
        "\n",
        "model = EnhancedSeqInfer(vocab_len, emsize, nhidden, nlayers, nfc, nclass, drop_prob)\n",
        "\n",
        "if test_model:\n",
        "    model.load_parameters('spoiler_net.params',ctx=ctx)\n",
        "    # model.load_parameters('model/esim-0.79.params', ctx=ctx)\n",
        "else:\n",
        "    model.initialize(init=init.Xavier(), ctx=ctx)\n",
        "# Attach a pre-trained glove word vector to the embedding layer\n",
        "model.embedding_layer.weight.set_data(indexer.vocab.embedding.idx_to_vec)\n",
        "# fixed the embedding layer\n",
        "model.embedding_layer.collect_params().setattr('grad_req', 'null')\n",
        "\n",
        "print(model)\n",
        "\n",
        "train_curve, valid_curve = [], []"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "EnhancedSeqInfer(\n",
            "  (embedding_layer): Embedding(40004 -> 300, float32)\n",
            "  (bilstm1): LSTM(None -> 300, TNC, num_layers=2, dropout=0.5, bidirectional)\n",
            "  (bilstm2): LSTM(None -> 300, TNC, dropout=0.5, bidirectional)\n",
            "  (align_att): AlignAttention(\n",
            "  \n",
            "  )\n",
            "  (output_layer): HybridSequential(\n",
            "    (0): Dense(None -> 256, Activation(tanh))\n",
            "    (1): Dropout(p = 0.5, axes=())\n",
            "    (2): Dense(None -> 256, Activation(tanh))\n",
            "    (3): Dropout(p = 0.5, axes=())\n",
            "    (4): Dense(None -> 2, linear)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gi9_E_D1D4SG"
      },
      "source": [
        "def calculate_loss(x_left, x_right, y, model, loss, class_weight):\n",
        "    pred, att = model(x_left, x_right)\n",
        "    y = nd.array(y.astype('int32', copy=False), ctx=ctx)\n",
        "    if loss_name == 'sce':\n",
        "        l = loss(pred, y)\n",
        "    elif loss_name == 'wsce':\n",
        "        l = loss(pred, y, class_weight, class_weight.shape[0])\n",
        "    else:\n",
        "        raise NotImplemented\n",
        "    return pred, l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9w2dwQ6pD4SG"
      },
      "source": [
        "def one_epoch(data_iter, model, loss, trainer, ctx, is_train, epoch, class_weight=None, loss_name='sce'):\n",
        "\n",
        "    loss_val = 0.\n",
        "    total_pred = []\n",
        "    total_true = []\n",
        "    n_batch = 0\n",
        "\n",
        "    for batch_x_left, batch_x_right, batch_y in data_iter:\n",
        "        batch_x_left = batch_x_left.as_in_context(ctx)\n",
        "        batch_x_right = batch_x_right.as_in_context(ctx)\n",
        "        batch_y = batch_y.as_in_context(ctx)\n",
        "\n",
        "        if is_train:\n",
        "            with autograd.record():\n",
        "                batch_pred, l = calculate_loss(batch_x_left, batch_x_right, \\\n",
        "                                               batch_y, model, loss, class_weight)\n",
        "\n",
        "            # backward calculate\n",
        "            l.backward()\n",
        "\n",
        "            # update parmas\n",
        "            trainer.step(batch_x_left.shape[0])\n",
        "\n",
        "        else:\n",
        "            batch_pred, l = calculate_loss(batch_x_left, batch_x_right, \\\n",
        "                                           batch_y, model, loss, class_weight)\n",
        "\n",
        "        # keep result for metric\n",
        "        batch_pred = nd.argmax(nd.softmax(batch_pred, axis=1), axis=1).asnumpy()\n",
        "        batch_true = np.reshape(batch_y.asnumpy(), (-1, ))\n",
        "        total_pred.extend(batch_pred.tolist())\n",
        "        total_true.extend(batch_true.tolist())\n",
        "        \n",
        "        batch_loss = l.mean().asscalar()\n",
        "\n",
        "        n_batch += 1\n",
        "        loss_val += batch_loss\n",
        "\n",
        "        # check the result of traing phase\n",
        "        if is_train and n_batch % 400 == 0:\n",
        "            print('epoch %d, batch %d, batch_train_loss %.4f, batch_train_acc %.3f' %\n",
        "                  (epoch, n_batch, batch_loss, accuracy_score(batch_true, batch_pred)))\n",
        "\n",
        "    # metric\n",
        "    F1 = f1_score(np.array(total_true), np.array(total_pred), average='binary')\n",
        "    acc = accuracy_score(np.array(total_true), np.array(total_pred))\n",
        "    loss_val /= n_batch\n",
        "\n",
        "    if is_train:\n",
        "        print('epoch %d, learning_rate %.5f \\n\\t train_loss %.4f, acc_train %.3f, F1_train %.3f, ' %\n",
        "              (epoch, trainer.learning_rate, loss_val, acc, F1))\n",
        "        train_curve.append((acc, F1))\n",
        "        # declay lr\n",
        "        if epoch % 2 == 0:\n",
        "            trainer.set_learning_rate(trainer.learning_rate * 0.9)\n",
        "    else:\n",
        "        print('\\t valid_loss %.4f, acc_valid %.3f, F1_valid %.3f, ' % (loss_val, acc, F1))\n",
        "        valid_curve.append((acc, F1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hzq1S9DFD4SH"
      },
      "source": [
        "def train_valid(data_iter_train, data_iter_valid, model, loss, trainer, \\\n",
        "                ctx, nepochs, class_weight=None, loss_name='sce'):\n",
        "\n",
        "    for epoch in range(1, nepochs+1):\n",
        "        start = time.time()\n",
        "        # train\n",
        "        is_train = True\n",
        "        one_epoch(data_iter_train, model, loss, trainer, ctx, is_train, epoch, class_weight, loss_name)\n",
        "\n",
        "        # valid\n",
        "        is_train = False\n",
        "        one_epoch(data_iter_valid, model, loss, trainer, ctx, is_train, epoch, class_weight, loss_name)\n",
        "        end = time.time()\n",
        "        print('time %.2f sec' % (end-start))\n",
        "        print(\"*\"*100)\n",
        "        model.save_parameters('spoiler_net_epoch_'+str(epoch)+'.params')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lV48e8jCD4SI"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbHbFiXnD4SI"
      },
      "source": [
        "class_weight = None\n",
        "loss_name = 'sce'\n",
        "optim_name = 'adam'\n",
        "lr = 0.001\n",
        "clip = 2.5\n",
        "nepochs = 10\n",
        "\n",
        "trainer = gluon.Trainer(model.collect_params(), optim_name, {'learning_rate': lr, 'clip_gradient': clip})\n",
        "\n",
        "if loss_name == 'sce':\n",
        "    loss = gluon.loss.SoftmaxCrossEntropyLoss()\n",
        "elif loss_name == 'wsce':\n",
        "    loss = WeightedSoftmaxCE()\n",
        "    # the value of class_weight is obtained by counting data in advance. It can be seen as a hyperparameter.\n",
        "    class_weight = nd.array([1., 3.], ctx=ctx)\n",
        "else:\n",
        "    print('loss function {} is not implemented!'.format(loss_name))\n",
        "    raise NotImplemented"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcciJ_13aa4m"
      },
      "source": [
        "!export MXNET_ENGINE_TYPE=NaiveEngine"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDD1NwzrD4SI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a850b8ce-f573-41ee-93cf-215973399dbb"
      },
      "source": [
        "# train and valid\n",
        "train_valid(train_dataloader, valid_dataloader, model, loss,trainer, ctx, nepochs, class_weight=class_weight, loss_name=loss_name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 1, learning_rate 0.00100 \n",
            "\t train_loss 0.5546, acc_train 0.737, F1_train 0.137, \n",
            "\t valid_loss 0.5380, acc_valid 0.756, F1_valid 0.032, \n",
            "time 113.44 sec\n",
            "****************************************************************************************************\n",
            "epoch 2, learning_rate 0.00100 \n",
            "\t train_loss 0.5372, acc_train 0.746, F1_train 0.230, \n",
            "\t valid_loss 0.5469, acc_valid 0.734, F1_valid 0.240, \n",
            "time 115.45 sec\n",
            "****************************************************************************************************\n",
            "epoch 3, learning_rate 0.00090 \n",
            "\t train_loss 0.5063, acc_train 0.761, F1_train 0.337, \n",
            "\t valid_loss 0.5376, acc_valid 0.748, F1_valid 0.203, \n",
            "time 115.26 sec\n",
            "****************************************************************************************************\n",
            "epoch 4, learning_rate 0.00090 \n",
            "\t train_loss 0.4861, acc_train 0.773, F1_train 0.379, \n",
            "\t valid_loss 0.5265, acc_valid 0.744, F1_valid 0.366, \n",
            "time 115.58 sec\n",
            "****************************************************************************************************\n",
            "epoch 5, learning_rate 0.00081 \n",
            "\t train_loss 0.4745, acc_train 0.779, F1_train 0.427, \n",
            "\t valid_loss 0.5551, acc_valid 0.748, F1_valid 0.074, \n",
            "time 115.47 sec\n",
            "****************************************************************************************************\n",
            "epoch 6, learning_rate 0.00081 \n",
            "\t train_loss 0.5126, acc_train 0.760, F1_train 0.304, \n",
            "\t valid_loss 0.5526, acc_valid 0.756, F1_valid 0.315, \n",
            "time 115.56 sec\n",
            "****************************************************************************************************\n",
            "epoch 7, learning_rate 0.00073 \n",
            "\t train_loss 0.4370, acc_train 0.805, F1_train 0.554, \n",
            "\t valid_loss 0.5373, acc_valid 0.772, F1_valid 0.337, \n",
            "time 115.65 sec\n",
            "****************************************************************************************************\n",
            "epoch 8, learning_rate 0.00073 \n",
            "\t train_loss 0.4004, acc_train 0.820, F1_train 0.608, \n",
            "\t valid_loss 0.5578, acc_valid 0.750, F1_valid 0.396, \n",
            "time 115.36 sec\n",
            "****************************************************************************************************\n",
            "epoch 9, learning_rate 0.00066 \n",
            "\t train_loss 0.3695, acc_train 0.840, F1_train 0.655, \n",
            "\t valid_loss 0.6179, acc_valid 0.756, F1_valid 0.455, \n",
            "time 115.63 sec\n",
            "****************************************************************************************************\n",
            "epoch 10, learning_rate 0.00066 \n",
            "\t train_loss 0.3436, acc_train 0.848, F1_train 0.686, \n",
            "\t valid_loss 0.5480, acc_valid 0.772, F1_valid 0.452, \n",
            "time 115.32 sec\n",
            "****************************************************************************************************\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7yjHLRXD4SJ"
      },
      "source": [
        "### Save the model and the training, validation curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSDqQfuHD4SJ"
      },
      "source": [
        "model.save_parameters('spoiler_net.params')#'model/esim-{:.4}.params'.format(str(valid_curve[-1][0])))\n",
        "with open('acc_record', 'w') as f:\n",
        "    f.write(str(train_curve)+'\\n')\n",
        "    f.write(str(valid_curve))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KZEpkz8U2Du"
      },
      "source": [
        "model = EnhancedSeqInfer(vocab_len, emsize, nhidden, nlayers, nfc, nclass, drop_prob)\n",
        "model.load_parameters('spoiler_net.params',ctx=ctx)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "gVKgIiBOSUpv"
      },
      "source": [
        "ctx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBIce13wD4SK"
      },
      "source": [
        "### Visualize the training and validation curves\n",
        "We can find in the plot that after how many epochs the model performs best on validation set without overfitting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBrLMqgmD4SK"
      },
      "source": [
        "from ast import literal_eval\n",
        "with open('acc_record', 'r') as f:\n",
        "    train_curve, valid_curve = [ literal_eval(line) for line in f]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "WJGQaTIbD4SK",
        "outputId": "473316bc-48e7-4e2c-c3b0-f81c454c7d66"
      },
      "source": [
        "train_acc = [ acc for acc, _ in train_curve ]\n",
        "train_f1 = [ f1 for _, f1 in train_curve ]\n",
        "valid_acc = [ acc for acc, _ in valid_curve ]\n",
        "valid_f1 = [ f1 for _, f1 in valid_curve ]\n",
        "epochs = [ i for i in range(1, len(valid_curve)+1) ]\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('Accuracy')\n",
        "plt.plot(epochs, train_acc, label='train', color='orange')\n",
        "plt.plot(epochs, valid_acc, label='validation', color='green')\n",
        "plt.legend(loc='upper left')\n",
        "plt.show()\n",
        "plt.title('F1')\n",
        "plt.plot(epochs, train_f1, label='train', color='orange')\n",
        "plt.plot(epochs, valid_f1, label='validation', color='green')\n",
        "plt.legend(loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6uWfzsyD4SK"
      },
      "source": [
        "### Test on randomly made up plot and review by myself\n",
        "Now we will randomly input a movie plot summary and its review to see if the model decide the review is a spoiler or not."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cyx8Gz_WexmQ",
        "outputId": "2f8a1d84-82e7-4838-eaab-35c4885c4387"
      },
      "source": [
        "data.columns\n",
        "print(left)\n",
        "# data[data.movie_id=='tt0499549']\n",
        "# data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The movie begins in the year 1967 with a pregnant woman being admitted to a hospital, bleeding from the neck. Paramedics think she was attacked by some type of animal. Doctors perform an emergency C-Section, and her baby (a boy) is born alive just as she dies.Thirty years later a young man named Dennis (Kenny Johnson) is riding in a car with an attractive redhead named Racquel (Traci Lords) heading to an underground nightclub (located, oddly, in a slaughterhouse) somewhere in Los Angeles. After addressing the doorman in Russian, Racquel brings the young man into the club. The man is confused and trying to understand the rules of the club. Some of the regulars indifferently push him aside. Saying he needs a drink, the sprinkler suddenly system activates, raining blood down on everyone inside. It is then that he (and the audience) realizes that everyone in the club is a vampire.Dennis desperately tries to get away and winds up at the feet of a menacing figure in a black-leather trenchcoat. The vampires look on this figure with awe, mumbling the words: \"it's the Daywalker!\" This is our first look at Blade (Wesley Snipes), the vampire killer.Blade pulls out a shotgun and opens fire on the vampires, who instantly burn to ashes when killed. When the gun is knocked out of his hands by Racquel, Blade uses a set of silver stakes to kill Racquel and more vampires, including the disk jockey. Soon all the vamps are either dead or have fled except for one; a heavyset vamp named Quinn (Donal Logue), whom Blade has apparently run into before. Blade pins Quinn to the wall, and then sets him on fire before confronting the last member in the club (the human man from the beginning). Finding no vampire bite marks on Dennis, Blade lets him live and makes his escape as the police arrive.Quinn is extinguished and taken to the local hospital. A morgue technician examines his blood and shows the results to Dr. Karen Jenson (N'Bushe Wright), who finds a number of irregularities, including abnormally developed jaw muscles. As they are discussing the test results, Quinn springs back to life and bites both doctors. Before he can finish Dr. Jenson, Blade shows up and saves her, cutting off one of Quinn's arms.Blade brings Karen to his hideout and asks for help from his mentor, an elderly man named named Whistler (Kris Kristofferson). Whistler injects Dr. Jenson with a solution of garlic essence and silver nitrate and remarks that she has a 50/50 chance of recovering.Meanwhile, a group of vampires are discussing Blade's latest attack on their members. Apparently this club (and to an extent, Quinn) is the property of a vampire named Deacon Frost (Stephen Dorff). Frost wants the vampires to outright rule the humans and use them as a food source while the others (particularly an older vampire named Dragonetti) prefer to maintain a peaceful co-existance. Dragonetti (Udo Kier) in particular does not like Frost because Frost is not a \"pure-blood\" (ie: was not born a vampire, merely became one through the bite of another). Frost is also arrogant and his & the actions of his followers draw unnecessary attention to the vampire underworld.The next morning, Jenson awakens and sees Whistler injecting Blade with some type of serum. She tries to run away but Whistler confronts her and tells her that he and Blade are hunting vampires. Karen of course is skeptical, but Whistler goes on to talk about what they use to hunt- explaining that vampires are severely allergic to silver & garlic while also being vulnerable to sunlight (ultraviolet rays in particular). Whistler fuels up Blade's car and gives him a new UV flashlight to use when hunting that night. Whistler also gives Karen a type of \"vampire mace\" (garlic & silver nitrate in a liquid form).Blade drops Karen off at her apartment and she tries to pack up and get out of town. A police officer, identifying himself as Officer Krieger (Kevin Patrick Walls), arrives and questions her about the events at the hospital last night, as a pretext for trying to attack her. Before he can kill her, Blade returns and subdues the policeman. Blade explains that this officer is a \"familiar,\" (also called a \"Reinfield\" or a \"bug-eater\") a human slave owned by a vampire. Blade reveals a tattoo called a \"glyph\" on the back of the officer's neck and recognizes it as the mark of Deacon Frost. Blade lets Officer Krieger go free in the hopes of tracking him to another vampire club.Sure enough, Blade and Karen arrive at a new underground club and have a confrontation with Pearl (Eric Edwards), a morbidly-obese vampire who works as a record keeper. Pearl confesses that Deacon Frost is researching ancient vampire prophecies... one in particular involving a ritual and a creature named \"La Magra.\" Karen burns Pearl severely with Whistler's giant UV light and Blade steals part of Pearl's hard drive.Blade and Karen move further into the vampire records and find pages from \"The Book of Erebus,\" the vampire Bible. They are suddenly ambushed by a group of vampires led by Quinn, now healed and having regrown his lost hand. Quinn tortures Blade for information (and for his own amusement) but realizes that Blade has a radio link in his ear.Whistler suddenly arrives (having been listening in the whole time) and opens fire on the vampires. The three heroes escape through the subway system, and Blade cuts off Quinn's other hand to get away. When he and Karen board a passing subway car, Blade steps back and injects himself with more serum. Karen suspects that Blade is actually a vampire himself, but Blade responds in the negative; he is something completely different.At a vampire club, Officer Krieger arrives where he reports to Frost about Blade and of his new alliance with the doctor, Karen. Frost is angry for letting Blade get away, but does not kill Krieger. Frost lets his blond vamp girlfriend Mercury (Arly Jover) biting out Krieger's throat in gory fashion.Back at the hideout, Whistler explains Blade's history to Karen: Blade was the baby seen in the opening scene; his mother was attacked by a vampire hours before he was born. She died but Blade lived and Whistler found him on the streets. Due to the unique circumstances of his birth, Blade is a hybrid of human and vampire abilities; he can resist garlic and silver, can walk in open sunlight (hence the nickname \"Daywalker\" given by other vampires) and has enhanced strength and healing abilities just like other vampires, however he also has inherited the vampire's thirst for blood. Whistler developed a serum to curb Blade's cravings, but Blade's body is starting to resist it. Whistler also gives Karen a bit of his own history: his own children and wife were killed by a vampire years before and he acts out of revenge, as much as social justice. Whistler also shares his own history: he was married with children and one night while they were all home, a vampire held Whistler and his family hostage. The vampire killed them all but left Whistler himself alive. Blade also confides in Karen that Whistler is suffering from the middle stages of cancer, but is refusing treatment in order to help in Blade's war against the vampires.Whistler also learns that his attempted cure of Karen was ineffective and that she is growing close to turning into a vampire. Karen refuses to give up, taking a few items from the hospital where she worked to try and find a cure for both her and Blade. The first item she brings (an anti-coagulant formula known as EDTA) is found to have a violent reaction when mixed with vampire blood, so she gives it to Blade for use as a weapon.Meanwhile, Quinn is at Frosts' headquarters, berated for his second failure. Frost encourages Quinn to go back out and get Blade... alive. Quinn is confused by the order since the vampires have been trying to kill Blade for a very long time.Afterwords, Frost takes Mercury and his entourage of followers and abducts Dragonetti, taking him to a beach near sunrise and forcibly ripping out the elder vampire's fangs. Frost's gang shields themselves with sunscreen, black clothing and motorcycle helmets, leaving Dragonetti to burn to death in the sun. Frost confronts the remaining elders of the Vampire Council, asking for 12 people to \"volunteer\" for his \"La Magra\" project.While Blade purchases more items for hunting, Whistler and Karen discuss her latest attempt at a cure. Karen is sure that the new formula will work on her, but is unsure what effects it might have on Blade since he was born with vampirism. The stronghold is attacked by Frost's followers and Karen is abducted while Whistler is brutally beaten by the vampires.Blade returns to find Whistler in severe pain and infected by the vampire bites. In an emotional scene, Blade assists Whistler in committing suicide before loading up to raid Frost's stronghold.Blade attacks the Frost compound and kills many of Frosts' followers, even trying the EDTA formula (which makes vampires swell up and explode in a shower of blood). Blade finally reaches the final room of Frost's hideout, where he is confronted by a lone woman who calls him \"Eric.\" It is Blade's mother, reborn as a vampire to serve Frost.Frost ambushes Blade, taking him hostage while revealing that HE (Frost) was the vampire who bit Blade's mother. Blade and Karen are transported to another location. Blade, despondent, asks Karen if she has finished her \"miracle cure.\" Karen says that the cure would presumably rob Blade of his strength and healing powers while neutralizing his thirst, effectively making Blade fully human.Blade and the 12 members of the Vampire Council are to be used as offerings for Frost's \"La Magra\" ritual. Blade is put into a large torture device, where most of his blood is extracted for the ritual. The 12 members of the Council are executed and their souls are absorbed by Frost, turning him into La Magra: the Blood God.Karen escapes using the mace previously given to her by Whistler, and frees Blade - now terribly weak. Knowing that there is only one way to get Blade healed in time, Karen requests that Blade take some of her blood. Blade resists at first, but finally seeing no other choice, bites Karen.Blade's mother suddenly appears and fights Blade, ultimately being stabbed in the heart with a bone. Blade fights his way through the remaining vampire guards, reclaiming his trademark sword and decapitating Quinn to reclaim his sunglasses. Blade then takes on the vampire guards in marital-arts fashion, defeating them all. Mercury attempts to kill Karen who opens fire with a shotgun containing silver buckshot, but Mercury is too fast and knocks the gun out of Karen's hands and easily bests her in hand-to-hand combat. Karen finally kills Mercury by using the garlic mace to spray Mercury in her mouth just as she is about to bite Karen, making Mercury's head explode in a gory mass of blood and brains.Blade and Frost/La Magra fight, effectively clashing swords. Blade cuts off Magra's arm and slices him in half, but the Blood God merely regenerates without any effort. La Magra taunts Blade, mentioning the \"serum\" that Blade is so dependent on. Blade realizes that Magra is actually referring to the EDTA vials that Blade brought on the hunt. He grabs the packet of vials and unloads every one into the Blood God. La Magra swells up and explodes in a massive shower of blood.Karen and Blade exit the ruins. Blade finally declines the cure, deciding that even with Frost gone there are many other vampires out there and he needs the additional skills. Blade asks Karen to make him a more efficient serum, and she agrees.The movie ends with Blade resuming his hunt for vampires in a Russian-speaking country.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CV08leBzD4SL"
      },
      "source": [
        "# right = \"When Thor's evil brother, Loki (Tom Hiddleston), gains access to the unlimited power of the energy cube called the Tesseract, Nick Fury (Samuel L. Jackson), director of S.H.I.E.L.D., initiates a superhero recruitment effort to defeat the unprecedented threat to Earth. Joining Fury's dream team are Iron Man (Robert Downey Jr.), Captain America (Chris Evans), the Hulk (Mark Ruffalo), Thor (Chris Hemsworth), the Black Widow (Scarlett Johansson) and Hawkeye (Jeremy Renner).\"\n",
        "# right =  'Tim killed Tom on a winter evening, and Sarah saw this scene.'\n",
        "# left = 'Thor'#'Sarah saw Tom killed, it is Tim to blame'\n",
        "left = str(data[data.movie_id=='tt0120611'].sentence1[0:1].values[0])\n",
        "# right = \"Circa 2154. The US army lands up in Pandora, an earth-sized moon in outer space. Their objective: to extract the much-needed minerals from Pandora's soil. But before they can do that, they must fight the peace-loving indigenous inhabitants of the alien world, relocate or destroy them with their spies and bombs.\"\n",
        "# right = \"Great movie. It lives up to its hype and does not disappoint. I would recommend watching the extended version if you haven't already to this point. It explains the story and plot more better and doesn't leave you confused and pondering on trying to figure out the plot and what could've actually happened that didn't made sense. Because when I saw the theatrical release, I knew it didn't feel complete and there was some plot holes that didn't really fill in certain segments of the movie. The CGI \"\n",
        "# right = str(data[data.movie_id=='tt0499549'].sentence1[0:1].values[0])\n",
        "right = left#\"Neytiri (Zoe Saldana) kills Quaritch and she helps Jake (Sam Worthington) just as he's on the brink of dying after he gets knocked out of the pod where he's linked to his Na'vi body. The military forces go back to Earth and a few trustworthy humans, such as Jake and Norm, stay on Pandora. A ritual at the Tree of Souls is performed and Jake's mind is transferred permanently to his Na'vi body.\"\n",
        "\n",
        "left_token = indexer.vocab[tokenizer.tokenizer(left)]\n",
        "right_token = indexer.vocab[tokenizer.tokenizer(right)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3y01FZTD4SL",
        "outputId": "91a83341-ed61-4fec-ff78-92425c82105b"
      },
      "source": [
        "# mz.\n",
        "# model.collect_params().initialize(force_reinit=True, ctx=mx.gpu())\n",
        "left_input = nd.array(left_token, ctx=ctx).reshape(1,-1)\n",
        "right_input = nd.array(right_token, ctx=ctx).reshape(1,-1)\n",
        "\n",
        "pred, att = model(left_input, right_input)\n",
        "pred, nd.argmax(pred, axis=1).asscalar()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(\n",
              " [[ 0.358205   -0.35204744]]\n",
              " <NDArray 1x2 @gpu(0)>, 0.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WNJ1aN3QrcO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLGdv48sUs6f"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}